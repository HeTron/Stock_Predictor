{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe46bdef72dbb662",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "requestResponse = requests.get('https://api.tiingo.com/tiingo/daily/nvda/prices?startDate=2012-1-1&token=3ab68f4b54224a51847d25a4dc930dfa87b55e2a', headers=headers)\n",
    "\n",
    "api_data = requestResponse.json()\n",
    "stock_df = pd.DataFrame(api_data)\n",
    "raw_df = stock_df.copy()\n",
    "NVDA_raw_csv = '/Users/jocksolo/PycharmProjects/trading_advisor/data'\n",
    "stock_df['date'] = pd.to_datetime(stock_df['date'], errors='coerce')\n",
    "stock_df['date'] = stock_df['date'].dt.date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "838f61145911be0c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index_response = requests.get('https://api.tiingo.com/tiingo/daily/qqq/prices?startDate=2012-1-1&token=3ab68f4b54224a51847d25a4dc930dfa87b55e2a', headers=headers)\n",
    "\n",
    "qqq_data = index_response.json()\n",
    "qqq_df = pd.DataFrame(qqq_data)\n",
    "qqq_df['date'] = pd.to_datetime(qqq_df['date'], errors='coerce')\n",
    "qqq_df['date'] = qqq_df['date'].dt.date\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2aa45864dc7a0066",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "volatility_data = requests.get(\"https://api.tiingo.com/tiingo/daily/vxx/prices?startDate=2012-1-1&token=3ab68f4b54224a51847d25a4dc930dfa87b55e2a\", headers=headers)\n",
    "\n",
    "vxx_data = volatility_data.json()\n",
    "vxx_df = pd.DataFrame(vxx_data)\n",
    "vxx_df['date'] = pd.to_datetime(vxx_df['date'], errors='coerce')\n",
    "vxx_df['date'] = vxx_df['date'].dt.date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5ceb5d6cfcc5487",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stock_df['vxx_adj_close'] = vxx_df['adjClose']\n",
    "stock_df['index_adj_close'] = qqq_df['adjClose']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c1d062e73e86746",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Implementing my own RSI calculation\n",
    "delta = stock_df['adjClose'].diff(1)\n",
    "delta.dropna(inplace=True)\n",
    "\n",
    "positive = delta.copy()\n",
    "negative = delta.copy()\n",
    "\n",
    "positive[positive < 0] = 0\n",
    "negative[negative > 0] = 0\n",
    "\n",
    "days = 14\n",
    "\n",
    "average_gain = positive.rolling(window=days).mean()\n",
    "average_loss = abs(negative.rolling(window=days).mean())\n",
    "\n",
    "relative_strength = average_gain / average_loss\n",
    "RSI = 100.0 - (100.0 / (1.0 + relative_strength))\n",
    "\n",
    "combined = pd.DataFrame()\n",
    "combined['adjClose'] = stock_df['adjClose']\n",
    "combined['RSI'] = RSI\n",
    "stock_df['RSI'] = RSI\n",
    "stock_df.dropna(subset=['RSI'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "550a51c3cdd3a090",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(combined.index, combined['adjClose'], color='lightgray')\n",
    "ax1.set_title('Adjusted Close Price', color='white')\n",
    "\n",
    "ax1.grid(True, color='#555555')\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.set_facecolor('black')\n",
    "ax1.figure.set_facecolor('#121212')\n",
    "ax1.tick_params(axis='x', colors='white')\n",
    "ax1.tick_params(axis='y', colors='white')\n",
    "\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "ax2.plot(combined.index, combined['RSI'], color='lightgray')\n",
    "ax2.axhline(0, linestyle='--',alpha=0.5, color='#ff0000')\n",
    "ax2.axhline(10, linestyle='--',alpha=0.5, color='#ffaa00')\n",
    "ax2.axhline(20, linestyle='--',alpha=0.5, color='#00ff00')\n",
    "ax2.axhline(30, linestyle='--',alpha=0.5, color='#cccccc')\n",
    "ax2.axhline(70, linestyle='--',alpha=0.5, color='#cccccc')\n",
    "ax2.axhline(80, linestyle='--',alpha=0.5, color='#00ff00')\n",
    "ax2.axhline(90, linestyle='--',alpha=0.5, color='#ffaa00')\n",
    "ax2.axhline(100, linestyle='--',alpha=0.5, color='#ff0000')\n",
    "\n",
    "ax2.set_title('RSI Value')\n",
    "ax2.grid(False)\n",
    "ax2.set_axisbelow(True)\n",
    "ax2.set_facecolor('black')\n",
    "ax2.tick_params(axis='x', colors='white')\n",
    "ax2.tick_params(axis='y', colors='white')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4c1a69cf31c9837",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stock_df.drop(['divCash', 'splitFactor'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1726ba4f8489dea2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stock_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "991c9e0ee591747f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Selecting features\n",
    "feature_list = ['adjClose', 'close', 'high', 'low', 'open', 'volume', 'adjHigh', 'adjLow', 'adjOpen', 'adjVolume', 'index_adj_close', 'vxx_adj_close', 'RSI']\n",
    "features_df = stock_df[feature_list]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c3606362f4234bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corr_matrix = features_df.corr()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "460d5764c23d1c00",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corr_matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b9dff528d3bb53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cf56f33e065e646",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "208c237dadefea9a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "prediction_days = 10\n",
    "\n",
    "historical_data = []\n",
    "target = []\n",
    "\n",
    "for i in range(window_size, len(features_df) - prediction_days):\n",
    "    historical_data.append(scaled_features[i-window_size:i])\n",
    "    target.append(scaled_features[i:i+prediction_days, features_df.columns.get_loc('adjClose')])  # Assuming you want to predict 'adjClose'\n",
    "\n",
    "historical_data, target = np.array(historical_data), np.array(target)\n",
    "target = np.reshape(target, (target.shape[0], target.shape[1]))  # Reshape y_train if necessary\n",
    "\n",
    "# Splitting datasets\n",
    "x_train_set, x_test_set, y_train_set, y_test_set = train_test_split(historical_data, target, test_size=0.2, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39ee9c2a6876fd7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(window_size, len(feature_list))),  # Explicitly define the input shape\n",
    "    LSTM(units=50,return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=prediction_days)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "448b57e2ec8fb068",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca8c156123466422",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training the model (Adjust epochs and batch_size according to your dataset)\n",
    "model.fit(x_train_set, y_train_set, epochs=50, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2d52cf9cca8c45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "train_loss = model.evaluate(x_train_set, y_train_set, verbose=0)\n",
    "test_loss = model.evaluate(x_test_set, y_test_set, verbose=0)\n",
    "print(f\"Train Loss: {train_loss}, Test Loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edc545a1e057ab92",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Predicting the last 60 days from the test set\n",
    "predicted = model.predict(x_test_set[-1].reshape(1, window_size, len(feature_list)))\n",
    "\n",
    "print(predicted)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ad5a8151846d10d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize a dummy array with zeros\n",
    "dummy_array = np.zeros((predicted.shape[1], len(feature_list)))\n",
    "\n",
    "# Insert the predictions into the first column of each row of the dummy array\n",
    "for i in range(predicted.shape[1]):  # Iterate over each of the 10 predictions\n",
    "    dummy_array[i, 0] = predicted[0, i]  # Assign each prediction to the 'adjClose' column\n",
    "    \n",
    "# Inverse transform the entire dummy array\n",
    "predicted_prices_full = scaler.inverse_transform(dummy_array)\n",
    "\n",
    "# Extract the inversely transformed predictions for 'adjClose'\n",
    "predicted_prices = predicted_prices_full[:, 0]\n",
    "\n",
    "predicted_prices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bddf06642e19f09",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Testing the accuracy by splitting it into different time frames\n",
    "stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "stock_df.sort_values('date', inplace=True)\n",
    "\n",
    "# Choosing a split date for demonstration (adjust as needed)\n",
    "split_date = pd.Timestamp('2023-01-01')\n",
    "\n",
    "# Splitting the dataset into training and testing based on the split date\n",
    "train_df = stock_df[stock_df['date'] < split_date]\n",
    "test_df = stock_df[stock_df['date'] >= split_date]\n",
    "\n",
    "# Fit the scaler on the training data only, then transform both train and test sets\n",
    "scaler.fit(train_df[feature_list])\n",
    "scaled_train = scaler.transform(train_df[feature_list])\n",
    "scaled_test = scaler.transform(test_df[feature_list])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d939acdeb89100d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size, prediction_days):\n",
    "    x, y = [], []\n",
    "    for i in range(window_size, len(data) - prediction_days):\n",
    "        x.append(data[i-window_size:i])\n",
    "        y.append(data[i:i+prediction_days, 0])  # Predicting 'adjClose'\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_train, y_train = create_sequences(scaled_train, window_size, prediction_days)\n",
    "x_test, y_test = create_sequences(scaled_test, window_size, prediction_days)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ae320b8b69f964f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_model = Sequential([\n",
    "    Input(shape=(window_size, len(feature_list))),\n",
    "    LSTM(units=50, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=prediction_days)\n",
    "])\n",
    "\n",
    "test_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "test_model.fit(x_train, y_train, epochs=25, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18bf7db3fa27f9b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = test_model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53b45a64e32f0bc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize a dummy array with zeros\n",
    "dummy_array_2 = np.zeros((predictions.shape[1], len(feature_list)))\n",
    "\n",
    "# Insert the predictions into the first column of each row of the dummy array\n",
    "for i in range(predictions.shape[1]):  # Iterate over each of the 10 predictions\n",
    "    dummy_array_2[i, 0] = predictions[0, i]  # Assign each prediction to the 'adjClose' column\n",
    "    \n",
    "# Inverse transform the entire dummy array\n",
    "predictions_prices_full = scaler.inverse_transform(dummy_array_2)\n",
    "\n",
    "# Extract the inversely transformed predictions for 'adjClose'\n",
    "predicted_prices_test = predictions_prices_full[:, 0]\n",
    "\n",
    "predicted_prices_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a04b3ca42a3eafa3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stock_df.set_index('date', inplace=True)\n",
    "target = 'adjClose'\n",
    "new_scaled_data = scaler.fit_transform(stock_df[feature_list])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "843f74a025c57aff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x, y = create_sequences(new_scaled_data, window_size, prediction_days)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bdfd539b692af75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(x):\n",
    "    x_train_2, x_test_2 = x[train_index], x[test_index]\n",
    "    y_train_2, y_test_2 = y[train_index], y[test_index]\n",
    "    \n",
    "    # Define LSTM Model\n",
    "    test_model_2 = Sequential([\n",
    "        Input(shape=(window_size, len(feature_list))),\n",
    "        LSTM(50, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(prediction_days)  # Predicting 'prediction_days' into the future\n",
    "    ])\n",
    "    \n",
    "    test_model_2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    test_model_2.fit(x_train_2, y_train_2, epochs=25, batch_size=16)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss = test_model_2.evaluate(x_test_2, y_test_2)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    \n",
    "    # Make predictions (Optional: inverse transform and compare against actual values)\n",
    "    predictions = test_model_2.predict(x_test_2)\n",
    "    # Assuming you want to inverse transform the last set of predictions for visualization or comparison\n",
    "    if test_index[-1] == x.shape[0] - 1:  # Check if it's the last split\n",
    "        # Prepare predictions for inverse transform\n",
    "        predictions_full = np.zeros((predictions.shape[0], new_scaled_data.shape[1]))\n",
    "        predictions_full[:, 0] = predictions[:, -1]  # Assuming we're only interested in the last prediction day\n",
    "        predicted_prices = scaler.inverse_transform(predictions_full)[:, 0]\n",
    "        print(predicted_prices)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b4f828a052f3dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming stock_df is your DataFrame and it's indexed by date\n",
    "last_date = stock_df.index.max()\n",
    "\n",
    "# Generate future dates starting from the day after the last date\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=len(predicted_prices), freq='D')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot historical adjClose prices\n",
    "plt.plot(stock_df.index, stock_df['adjClose'], label='Historical adjClose')\n",
    "\n",
    "# Plot predicted prices\n",
    "plt.plot(future_dates, predicted_prices, label='Predicted adjClose', linestyle='--', color='red')\n",
    "\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  # Rotate dates for better readability\n",
    "plt.tight_layout()  # Adjust layout to make room for the rotated date labels\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "341485e2ea8f1cfe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "features_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7539c51731ad7104",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_features = new_scaled_data.shape[1]  # Number of features in your scaled data\n",
    "\n",
    "# Calculate the starting index for the sequences leading up to the last 10 days\n",
    "start_index = len(new_scaled_data) - 10 - window_size\n",
    "\n",
    "# Initialize x_test to an empty list\n",
    "x_test = []\n",
    "\n",
    "# Create sequences for x_test\n",
    "for i in range(10):  # We want 10 sequences leading up to the final 10 days\n",
    "    end_index = start_index + window_size + i\n",
    "    x_test.append(new_scaled_data[end_index - window_size:end_index])\n",
    "\n",
    "# Convert x_test to a numpy array and ensure its shape is (10, window_size, num_features)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "# Expected shape: (10, window_size, num_features)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d0ffc61c302f212",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the index to split the data so the last 10 days are reserved for testing\n",
    "test_size = 10  # days\n",
    "train_test_split_index = len(stock_df) - test_size\n",
    "    \n",
    "# Split your data into training and testing sets\n",
    "train_df = stock_df.iloc[:train_test_split_index]\n",
    "test_df = stock_df.iloc[train_test_split_index - window_size:]  # Include window_size days prior to test for input sequence\n",
    "    \n",
    "scaled_train = scaler.fit_transform(train_df)\n",
    "scaled_test = scaler.transform(test_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78fed9a350001e76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Prepare sequences for LSTM\n",
    "def create_sequences_with_target(data, window_size, prediction_days, include_target=True):\n",
    "    x, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        x.append(data[i-window_size:i])\n",
    "        if include_target:\n",
    "            # Assumes 'adjClose' is the first column after scaling\n",
    "            y.append(data[i:(i + prediction_days if i + prediction_days < len(data) else len(data)), 0])\n",
    "    return np.array(x), np.array(y) if include_target else np.array(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "714067ed008945fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prediction_days = 1  # Assuming 1 day prediction for simplicity; adjust as needed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9421f61ff5f1fa7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Creating training sequences\n",
    "x_train, y_train = create_sequences_with_target(scaled_train, window_size, prediction_days)\n",
    "\n",
    "# For testing, we'll only need the input sequences, excluding the last 10 days for target\n",
    "x_test, _ = create_sequences_with_target(scaled_test, window_size, prediction_days, include_target=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9b95dc6acd70055",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=25, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c6bd26f4790646",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Make predictions for the last 10 days\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Prepare predictions for inverse scaling\n",
    "# Assuming 'adjClose' is the first column in your scaled data\n",
    "predictions_full = np.zeros((len(predictions), new_scaled_data.shape[1]))\n",
    "predictions_full[:, 0] = predictions[:, -1]  # Assuming you are predicting one day ahead and want the last prediction\n",
    "\n",
    "# Inverse transform the predictions to the original scale\n",
    "predicted_prices = scaler.inverse_transform(predictions_full)[:, 0]\n",
    "\n",
    "# Extract the actual prices for the last 10 days\n",
    "actual_prices = stock_df['adjClose'][-10:].values\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df198b7c3ef7a82c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualizing the predicted vs actual prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "dates = stock_df.index[-10:]  # Extract dates for the last 10 days\n",
    "plt.plot(dates, actual_prices, label='Actual Prices', marker='o', color='blue')\n",
    "plt.plot(dates, predicted_prices, label='Predicted Prices', marker='x', linestyle='--', color='red')\n",
    "plt.title('Comparison of Actual and Predicted Prices for the Last 10 Days')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8188c2203c5d7194",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_prices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a9bb4cb4415fe79",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming 'stock_df' has a datetime index\n",
    "last_10_dates = stock_df.index[-10:]\n",
    "\n",
    "predicted_prices_df = pd.DataFrame({\n",
    "    'Date': last_10_dates,\n",
    "    'PredictedPrices': predicted_prices\n",
    "})\n",
    "\n",
    "print(predicted_prices_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af740963e9c61cc3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Using the 'last_10_dates' extracted above and assuming 'actual_prices' and 'predicted_prices' are available\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(last_10_dates, actual_prices, label='Actual Prices', marker='o', color='blue')\n",
    "plt.plot(last_10_dates, predicted_prices, label='Predicted Prices', marker='x', linestyle='--', color='red')\n",
    "plt.title('Comparison of Actual and Predicted Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.xticks(rotation=45)  # Rotate date labels for better readability\n",
    "plt.legend()\n",
    "plt.tight_layout()  # Adjust layout to ensure everything fits without overlap\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f0355b2bb1aec8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate daily changes for actual and predicted prices\n",
    "actual_changes = np.diff(actual_prices.flatten())\n",
    "predicted_changes = np.diff(predicted_prices.flatten())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d66ecad4bba88ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compare signs of the daily changes to see if they match (both positive or both negative)\n",
    "direction_matches = np.sign(actual_changes) == np.sign(predicted_changes)\n",
    "\n",
    "# Calculate the ratio or percentage of matches\n",
    "directional_accuracy = np.mean(direction_matches) * 100\n",
    "\n",
    "print(f\"Directional accuracy: {directional_accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f471a472ac46ece",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "scaled_data = scaler.fit_transform(features_df[feature_list].values)\n",
    "\n",
    "# Splitting data into training and \"testing\" where testing data is actually the data to predict the next 10 days\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(window_size, len(scaled_data) - prediction_days):\n",
    "    x_train.append(scaled_data[i - window_size:i])\n",
    "    y_train.append(scaled_data[i:i + prediction_days, features_df.columns.get_loc('adjClose')])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_to_predict = scaled_data[-(window_size + prediction_days):-prediction_days].reshape(1, window_size, len(feature_list))\n",
    "\n",
    "# Defining the LSTM Model\n",
    "prediction_model = Sequential([\n",
    "    Input(shape=(window_size, len(feature_list))),\n",
    "    LSTM(50, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=10)  # Predicting 'prediction_days' into the future\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "prediction_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "prediction_model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions for the next 10 days\n",
    "predicted_prices = prediction_model.predict(x_to_predict)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d57dcafe35f7275",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_prices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d79dc91cddd88b9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize a dummy array with zeros\n",
    "dummy_array_3 = np.zeros((predicted_prices.shape[1], len(feature_list)))\n",
    "\n",
    "# Insert the predictions into the first column of each row of the dummy array\n",
    "for i in range(predicted_prices.shape[1]):  # Iterate over each of the 10 predictions\n",
    "    dummy_array_3[i, 0] = predicted_prices[0, i]  # Assign each prediction to the 'adjClose' column\n",
    "    \n",
    "# Inverse transform the entire dummy array\n",
    "predictions_prices_full = scaler.inverse_transform(dummy_array_3)\n",
    "\n",
    "# Extract the 'adjClose' predictions after inverse scaling\n",
    "predicted_adjClose = predictions_prices_full[:, 0]  # 'adjClose' is the first feature\n",
    "\n",
    "print(\"Predicted 'adjClose' prices for the next 10 days:\")\n",
    "print(predicted_adjClose)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8f9ff348b9fa941",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_adjClose"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec43669059e7f492",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Use today's date as the last known date\n",
    "last_known_date = datetime.date.today()\n",
    "\n",
    "# Generate the next 10 business days (weekdays) for predictions starting from the day after today\n",
    "prediction_dates = pd.date_range(start=last_known_date + datetime.timedelta(days=1), periods=10, freq='B')\n",
    "\n",
    "# Assuming 'predicted_adjClose' contains your 10 predicted 'adjClose' prices\n",
    "predictions_table = pd.DataFrame({\n",
    "    'Date': prediction_dates,\n",
    "    'Predicted Adj Close': predicted_adjClose\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(predictions_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "540b89c65e94e214",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path = '/Users/jocksolo/PycharmProjects/trading_advisor/trading_advisor_model.keras'\n",
    "  # Change this to your desired path\n",
    "model.save(model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d3b874de4fd7306",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stock_df.to_csv('NVDA_historical_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b00bbcbbf154f16f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "165427dbda1dce1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
